# LLM Chat API Dependencies

# Web Framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0

# Data Validation
pydantic>=2.6.0
pydantic-settings>=2.1.0
jsonschema>=4.21.0

# Redis
redis>=5.0.0

# OpenAI Client (for vLLM)
openai>=1.10.0

# Token Counting
tiktoken>=0.7.0

# SSE Streaming
sse-starlette>=2.0.0

# Environment
python-dotenv>=1.0.0

# Multipart Forms
python-multipart>=0.0.6

# HTTP Client
httpx>=0.26.0

# SerpApi
serpapi>=0.1.5

# Observability
structlog>=24.1.0
prometheus-client>=0.20.0
sentry-sdk[fastapi]>=1.40.0

# Vector Search (optional - for semantic search)
numpy>=1.26.0
sentence-transformers>=2.3.0

# PostgreSQL (Long-term Memory)
asyncpg>=0.29.0
pgvector>=0.3.0

# Document Processing (optional)
pypdf>=4.0.0
python-docx>=1.1.0
